{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3 Linear Regression Example with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Feature Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in reviews:\n",
    "    sentences.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300    \n",
    "min_word_count = 40   \n",
    "num_workers = 4       \n",
    "context = 10          \n",
    "downsampling = 1e-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "   level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-18 16:05:04,071 : INFO : collecting all words and their counts\n",
      "2021-03-18 16:05:04,072 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-03-18 16:05:04,249 : INFO : PROGRESS: at sentence #10000, processed 1205223 words, keeping 51374 word types\n",
      "2021-03-18 16:05:04,452 : INFO : PROGRESS: at sentence #20000, processed 2396605 words, keeping 67660 word types\n",
      "2021-03-18 16:05:04,543 : INFO : collected 74065 word types from a corpus of 2988089 raw words and 25000 sentences\n",
      "2021-03-18 16:05:04,544 : INFO : Loading a fresh vocabulary\n",
      "2021-03-18 16:05:04,576 : INFO : effective_min_count=40 retains 8160 unique words (11% of original 74065, drops 65905)\n",
      "2021-03-18 16:05:04,577 : INFO : effective_min_count=40 leaves 2627273 word corpus (87% of original 2988089, drops 360816)\n",
      "2021-03-18 16:05:04,597 : INFO : deleting the raw counts dictionary of 74065 items\n",
      "2021-03-18 16:05:04,599 : INFO : sample=0.001 downsamples 30 most-common words\n",
      "2021-03-18 16:05:04,600 : INFO : downsampling leaves estimated 2494384 word corpus (94.9% of prior 2627273)\n",
      "2021-03-18 16:05:04,611 : INFO : estimated required memory for 8160 words and 300 dimensions: 23664000 bytes\n",
      "2021-03-18 16:05:04,612 : INFO : resetting layer weights\n",
      "2021-03-18 16:05:05,734 : INFO : training model with 4 workers on 8160 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2021-03-18 16:05:06,742 : INFO : EPOCH 1 - PROGRESS: at 45.44% examples, 1137563 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:07,750 : INFO : EPOCH 1 - PROGRESS: at 94.16% examples, 1168818 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:07,846 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-03-18 16:05:07,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-18 16:05:07,854 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-18 16:05:07,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-18 16:05:07,860 : INFO : EPOCH - 1 : training on 2988089 raw words (2494544 effective words) took 2.1s, 1175482 effective words/s\n",
      "2021-03-18 16:05:08,865 : INFO : EPOCH 2 - PROGRESS: at 46.47% examples, 1164104 words/s, in_qsize 6, out_qsize 1\n",
      "2021-03-18 16:05:09,874 : INFO : EPOCH 2 - PROGRESS: at 96.42% examples, 1197988 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:09,920 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-03-18 16:05:09,926 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-18 16:05:09,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-18 16:05:09,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-18 16:05:09,934 : INFO : EPOCH - 2 : training on 2988089 raw words (2494579 effective words) took 2.1s, 1204819 effective words/s\n",
      "2021-03-18 16:05:10,946 : INFO : EPOCH 3 - PROGRESS: at 45.77% examples, 1139520 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:11,949 : INFO : EPOCH 3 - PROGRESS: at 94.14% examples, 1168730 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:12,045 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-03-18 16:05:12,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-18 16:05:12,047 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-18 16:05:12,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-18 16:05:12,052 : INFO : EPOCH - 3 : training on 2988089 raw words (2494531 effective words) took 2.1s, 1179637 effective words/s\n",
      "2021-03-18 16:05:13,060 : INFO : EPOCH 4 - PROGRESS: at 44.81% examples, 1118267 words/s, in_qsize 8, out_qsize 0\n",
      "2021-03-18 16:05:14,066 : INFO : EPOCH 4 - PROGRESS: at 93.84% examples, 1164825 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:14,170 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-03-18 16:05:14,174 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-18 16:05:14,179 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-18 16:05:14,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-18 16:05:14,183 : INFO : EPOCH - 4 : training on 2988089 raw words (2494535 effective words) took 2.1s, 1171876 effective words/s\n",
      "2021-03-18 16:05:15,193 : INFO : EPOCH 5 - PROGRESS: at 46.80% examples, 1166227 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:16,202 : INFO : EPOCH 5 - PROGRESS: at 95.13% examples, 1178815 words/s, in_qsize 7, out_qsize 0\n",
      "2021-03-18 16:05:16,288 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-03-18 16:05:16,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-18 16:05:16,292 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-18 16:05:16,295 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-18 16:05:16,295 : INFO : EPOCH - 5 : training on 2988089 raw words (2494591 effective words) took 2.1s, 1182354 effective words/s\n",
      "2021-03-18 16:05:16,296 : INFO : training on a 14940445 raw words (12472780 effective words) took 10.6s, 1181005 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "           size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words, model, num_features):\n",
    "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
    "\n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "\n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features):\n",
    "    dataset = list()\n",
    "\n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "\n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-48cdc3edcd51>:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  feature_vector = np.add(feature_vector, model[w])\n"
     ]
    }
   ],
   "source": [
    "test_data_vecs = get_dataset(sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = test_data_vecs\n",
    "y = np.array(sentiments)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dacon/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862000\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %f\" % lgs.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "\n",
    "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)\n",
    "\n",
    "test_review = list(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naturally film main themes mortality nostalgia...</td>\n",
       "      <td>\"12311_10\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie disaster within disaster film full great...</td>\n",
       "      <td>\"8348_2\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie kids saw tonight child loved one point k...</td>\n",
       "      <td>\"5828_4\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afraid dark left impression several different ...</td>\n",
       "      <td>\"7186_2\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accurate depiction small time mob life filmed ...</td>\n",
       "      <td>\"12128_7\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review          id\n",
       "0  naturally film main themes mortality nostalgia...  \"12311_10\"\n",
       "1  movie disaster within disaster film full great...    \"8348_2\"\n",
       "2  movie kids saw tonight child loved one point k...    \"5828_4\"\n",
       "3  afraid dark left impression several different ...    \"7186_2\"\n",
       "4  accurate depiction small time mob life filmed ...   \"12128_7\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = list()\n",
    "for review in test_review:\n",
    "    test_sentences.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-48cdc3edcd51>:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  feature_vector = np.add(feature_vector, model[w])\n"
     ]
    }
   ],
   "source": [
    "test_data_vecs = get_dataset(test_sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "test_predicted = lgs.predict(test_data_vecs)\n",
    "\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "    \n",
    "ids = list(test_data['id'])\n",
    "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})\n",
    "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_w2v_answer.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-18 16:05:57,664 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2021-03-18 16:05:57,665 : INFO : not storing attribute vectors_norm\n",
      "2021-03-18 16:05:57,666 : INFO : not storing attribute cum_table\n",
      "2021-03-18 16:05:57,857 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
